# Left_to_do.md

## âœ… What Is Done
- Realtime audio streaming (STT and TTS) between frontend and backend
- Strict turn-taking: user cannot speak while TTS is playing
- No popups for audio: TTS plays in background
- Full chat UI with message history (alternating user/AI)
- Robust diagnostics/logging for TTS and WebSocket
- Bugfixes for TTS chunking, playback, and frontend/backend sync
- Documentation updated (README, PATH_UPDATES_SUMMARY.md)
- Branches: `fullstack_v2`, `v3_realtime_audio`

## ğŸ› ï¸ How & Method
- WebSocket for low-latency audio streaming
- Azure Speech Services for STT and TTS
- OpenAI GPT-4o for AI responses
- React (frontend), FastAPI (backend)
- State management with React hooks/refs
- Logging at every step for traceability

## â“ Why
- Needed natural, real-time, voice-only chat for Omani Arabic mental health
- Previous REST/audio upload approach was slow and unreliable
- Turn-taking is essential for natural conversation
- Diagnostics/logs are critical for debugging and reliability

## ğŸš§ What Is Remaining
- UI/UX polish (avatars, timestamps, mobile layout)
- Error handling (network, audio, backend failures)
- User settings (voice, speed, language, theme)
- Deployment scripts (Docker, CI/CD)
- Security review (CORS, auth, rate limiting)
- Automated tests (unit, integration, e2e)
- Multi-user/session support
- Analytics and logging dashboard
- Documentation for contributors

## ğŸ“ How Can Be Done
- UI: CSS modules/styled-components, add avatars, timestamps, responsive design
- Error handling: try/catch, user notifications, fallback UI
- Settings: Modal/settings page, localStorage for preferences
- Deployment: Dockerfiles, GitHub Actions, deployment scripts
- Security: CORS config, JWT/auth, input validation, rate limiting middleware
- Tests: Jest/React Testing Library (frontend), pytest (backend), e2e with Playwright/Cypress
- Multi-user: Add session IDs, user auth, scalable backend
- Analytics: Integrate with logging/monitoring tools (e.g., Sentry, ELK)
- Docs: CONTRIBUTING.md, code comments, architecture diagrams

## ğŸ”„ Alternatives
- Use Google or Amazon for STT/TTS (if Azure limits/costs)
- Use a state machine for turn-taking (XState, Redux)
- Use WebRTC for peer-to-peer audio (if scaling to 1:1 live)
- Use a queue/broker for TTS jobs (Celery, Redis)
- Use a monorepo tool (Nx, Turborepo) for better structure

## ğŸ¤” Why (Alternatives)
- Other cloud providers may offer better pricing or features
- State machines can make turn-taking logic more robust
- WebRTC is lower-latency for live calls, but more complex
- Queues help with scaling and reliability for TTS jobs
- Monorepo tools help with large, multi-team projects

## â„¹ï¸ Extra Info
- All major work is in `v3_realtime_audio` branch
- See `README.md` for setup and usage
- See `PATH_UPDATES_SUMMARY.md` for path/infra changes
- See daily logs in `documentation/7_13_2025.md`

## ğŸ—‚ï¸ Probable Full Project Structure
```
main project/
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â”œâ”€â”€ PATH_UPDATES_SUMMARY.md
â”œâ”€â”€ documentation/
â”‚   â”œâ”€â”€ 7_13_2025.md
â”‚   â”œâ”€â”€ COMPREHENSIVE_DEVELOPMENT_GUIDE.md
â”‚   â”œâ”€â”€ Left_to_do.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ai_systems/
â”‚   â”œâ”€â”€ main_system/
â”‚   â”‚   â”œâ”€â”€ omani_therapist_ai.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ claude_only/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ fullstack_realtime/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ frontend/
â”‚       â””â”€â”€ src/
â”‚           â””â”€â”€ MicStreamTranscriber.tsx
â”œâ”€â”€ speech_services/
â”‚   â”œâ”€â”€ text_to_speech/
â”‚   â””â”€â”€ speech_to_text/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ environment/
â””â”€â”€ tools/
    â””â”€â”€ security/
```

--- 